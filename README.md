word_tokenizer
==============
A WIP python 3 module purported to be an English tokenizer. Inspired by [NLTK](https://github.com/nltk/nltk/blob/master/nltk/tokenize/treebank.py).
